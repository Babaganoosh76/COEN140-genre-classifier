{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COEN 140 Final Project - Music Genre Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import librosa as lb\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_features(n=None):\n",
    "    return pd.read_csv('fma_metadata/features.csv', header=[0,1,2], index_col=0, nrows=n)\n",
    "\n",
    "def import_tracks(n=None, col=':'):\n",
    "    return pd.read_csv('fma_metadata/tracks.csv', header=[0,1], index_col=0, nrows=n)\n",
    "\n",
    "def import_genres(n=None):\n",
    "    return pd.read_csv('fma_metadata/genres.csv', header=0, index_col=0, nrows=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_song_features(name):\n",
    "    # Get the file path to an included audio example\n",
    "    file = os.path.join(os.getcwd(), \"test_songs\", name)\n",
    "    \n",
    "    # Load into waveform 'y', sampling rate 'sr'\n",
    "    y, sr = lb.load(file)\n",
    "    print('> \\'{}\\' successfully loaded'.format(name))\n",
    "\n",
    "    ## Extract all features\n",
    "    df = {}\n",
    "    \n",
    "    df[\"chroma_stft\"] = lb.feature.chroma_stft(y=y, sr=sr)\n",
    "    df[\"chroma_cqt\"] = lb.feature.chroma_cqt(y=y, sr=sr)\n",
    "    df[\"chroma_cens\"] = lb.feature.chroma_cens(y=y, sr=sr)\n",
    "    \n",
    "    df[\"tonnetz\"] = lb.feature.tonnetz(y=y, sr=sr)\n",
    "    df[\"mfcc\"] = lb.feature.mfcc(y=y, sr=sr)\n",
    "    \n",
    "    df[\"spectral_centroid\"] = lb.feature.spectral_centroid(y=y, sr=sr)\n",
    "    df[\"spectral_bandwidth\"] = lb.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    df[\"spectral_contrast\"] = lb.feature.spectral_contrast(y=y, sr=sr)\n",
    "    df[\"spectral_rolloff\"] = lb.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    \n",
    "    df[\"rmse\"] = lb.feature.rms(y=y)\n",
    "    df[\"zcr\"] = lb.feature.zero_crossing_rate(y=y)\n",
    "    \n",
    "    print('> Successfully extracted into dict')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/babaganoosh/Documents/SCU/COEN140/final_project/venv/lib/python3.7/site-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 'one_summers_day.mp3' successfully loaded\n",
      "> Successfully extracted into dict\n",
      "> Successfully applied statistics\n"
     ]
    }
   ],
   "source": [
    "## format new song features\n",
    "\n",
    "# fetch new song features as dict\n",
    "feat = get_song_features(\"one_summers_day.mp3\")\n",
    "\n",
    "# fetch empty array with correct format, then append empty row\n",
    "df = import_features(0).append(pd.Series(dtype=float), ignore_index=True)\n",
    "\n",
    "# apply stats to new song features\n",
    "stats = ['kurtosis','max','mean','median','min','skew','std']\n",
    "funcs = [scipy.stats.kurtosis, np.amax, np.mean, np.median, np.amin, scipy.stats.skew, np.std]\n",
    "\n",
    "for ft in df.columns.unique(0):\n",
    "    for st, fn in zip(stats, funcs):\n",
    "        df.loc[:,(ft,st)] = fn(feat[ft], axis=1)\n",
    "        \n",
    "print('> Successfully applied statistics')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_test_valid(X, y, drop_unique=False):\n",
    "    # parse genres into array\n",
    "    y = y.apply(lambda g: json.loads(g))\n",
    "    \n",
    "    # select/remove empty genres\n",
    "    eg = y.index[y.map(lambda g: len(g)==0)]\n",
    "    X = X.drop(eg)\n",
    "    y = y.drop(eg)\n",
    "    \n",
    "    # split into train/validate groups\n",
    "    Xt, Xv, yt, yv = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "    \n",
    "    # remove genres with only 1 entry\n",
    "    if drop_unique:\n",
    "        ug = yt.drop_duplicates(False).index\n",
    "        Xt = Xt.drop(ug)\n",
    "        yt = yt.drop(ug)\n",
    "    \n",
    "    return Xt, Xv, yt, yv\n",
    "\n",
    "def format_track_data(data, cols=None):\n",
    "    # select specified columns\n",
    "    data = data.loc[:,('track',cols)]\n",
    "    data.columns = cols\n",
    "    \n",
    "    # parse genres into array\n",
    "    data = data.applymap(lambda t: json.loads(t))\n",
    "    \n",
    "    return data\n",
    "\n",
    "def score(a, b):\n",
    "    assert len(a) == len(b), 'Arrays are not the same size'\n",
    "    \n",
    "    c = 0\n",
    "    for v1, v2 in zip(a,b):\n",
    "        if isinstance(v2, (int, np.integer)):\n",
    "            if (v1==v2):\n",
    "                c=c+1\n",
    "        else:\n",
    "            if v1 in v2:\n",
    "                c=c+1\n",
    "    return c/len(a)\n",
    "\n",
    "def print_scores(ts, vs, name='New'):\n",
    "    print('> {} Scores:'.format(name))\n",
    "    print('Training score: {:.3f}\\nValidation score: {:.3f}\\n'.format(ts, vs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Implementations\n",
    "### LDA Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m1_LDA(X, y, score_method='default', verbose=False):\n",
    "    #split data\n",
    "    Xt, Xv, yt, yv = train_test_split(X, y, test_size=0.2)\n",
    "    yt1 = yt.apply(lambda g: g[0])\n",
    "    \n",
    "    # fitting\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    lda.fit(Xt, yt1)\n",
    "    \n",
    "    # predictions\n",
    "    pt = lda.predict(Xt)\n",
    "    terr = score(pt,yt)\n",
    "    \n",
    "    pv = lda.predict(Xv)\n",
    "    verr = score(pv,yv)\n",
    "    \n",
    "    if verbose:\n",
    "        print_scores(terr, verr, 'LDA')\n",
    "    \n",
    "    return verr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QDA Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m2_QDA(X, y, score_method='default', verbose=False):\n",
    "    #split data\n",
    "    Xt, Xv, yt, yv = train_test_split(X, y, test_size=0.2)\n",
    "    yt1 = yt.apply(lambda g: g[0])\n",
    "    \n",
    "    # drop unique tracks\n",
    "    ug = yt1.drop_duplicates(False).index\n",
    "    Xt = Xt.drop(ug)\n",
    "    yt = yt.drop(ug)\n",
    "    yt1 = yt1.drop(ug)\n",
    "    \n",
    "    # fitting\n",
    "    qda = QuadraticDiscriminantAnalysis(tol=10**-10)\n",
    "    qda.fit(Xt, yt1)\n",
    "    \n",
    "    # predictions\n",
    "    pt = qda.predict(Xt)\n",
    "    terr = score(pt,yt)\n",
    "    \n",
    "    pv = qda.predict(Xv)\n",
    "    verr = score(pv,yv)\n",
    "    \n",
    "    if verbose:\n",
    "        print_scores(terr, verr, 'QDA')\n",
    "    \n",
    "    return verr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMC Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def m3_KMC(X, y, init_method='k-means++', verbose=False):\n",
    "    #split data\n",
    "    Xt, Xv, yt, yv = train_test_split(X, y, test_size=0.2)\n",
    "    yt1 = yt.apply(lambda g: g[0])\n",
    "    \n",
    "    # kmeans\n",
    "    centroids = yt1.drop_duplicates()\n",
    "    if init_method == 'centroids':\n",
    "        init_method = Xt.loc[centroids.index]\n",
    "    kmc = KMeans(n_clusters=len(centroids), init=init_method, n_init=10)\n",
    "    kmc.fit(Xt)\n",
    "    \n",
    "    # predictions\n",
    "    pt = pd.Series(kmc.predict(Xt), index=Xt.index)\n",
    "    for ci in pt.unique():\n",
    "        same_gen = pt[pt==ci].index.values\n",
    "        #print('{} entries in cluster {}'.format(len(same_gen), ci))\n",
    "        all_gen = np.concatenate(yt[same_gen].values)\n",
    "        mode_gen, cont_gen = scipy.stats.mode(all_gen)\n",
    "        pt.loc[same_gen] = mode_gen[0]\n",
    "    terr = score(pt,yt)\n",
    "    \n",
    "    pv = pd.Series(kmc.predict(Xv), index=Xv.index)\n",
    "    for ci in pv.unique():\n",
    "        same_gen = pv[pv==ci].index.values\n",
    "        mode_gen, cont_gen = scipy.stats.mode(np.concatenate(yv[same_gen].values))\n",
    "        pv.loc[same_gen] = mode_gen[0]\n",
    "    verr = score(pv,yv)\n",
    "    \n",
    "    if verbose:\n",
    "        print_scores(terr, verr, 'KMeans')\n",
    "    \n",
    "    return verr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "### Initial Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Data imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import data\n",
    "n = None # None = 106,574\n",
    "X = import_features(n)\n",
    "y = import_tracks(n)\n",
    "g = import_genres(n)\n",
    "\n",
    "# format genres properly\n",
    "cols = ['genres','genres_all']\n",
    "y = y.loc[:,('track',cols)]\n",
    "y.columns = cols\n",
    "y = y.applymap(lambda t: json.loads(t))\n",
    "\n",
    "# Remove entries with empty genres\n",
    "eg = y.index[y['genres'].map(lambda t: len(t)==0)]\n",
    "X = X.drop(eg)\n",
    "y = y.drop(eg)\n",
    "\n",
    "# Add another column holding parent genres\n",
    "y['top_level'] = y['genres'].apply(lambda t: [g.loc[t[0]]['top_level']])\n",
    "print('> Data imported successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = m1_LDA(X, y['genres'], verbose=True)\n",
    "lda = m1_LDA(X, y['genres_all'], verbose=True)\n",
    "lda = m1_LDA(X, y['top_level'], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('default')\n",
    "qda = m2_QDA(X, y['genres'], verbose=True)\n",
    "qda = m2_QDA(X, y['genres_all'], verbose=True)\n",
    "qda = m2_QDA(X, y['top_level'], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for km in ['k-means++', 'random', 'centroids']:\n",
    "    print('> Testing method: ', km)\n",
    "    m3_KMC(X, y['genres'], km, verbose=True)\n",
    "    m3_KMC(X, y['genres_all'], km, verbose=True)\n",
    "    m3_KMC(X, y['top_level'], km, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per Feature/Statistic Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "yc = 'top_level'\n",
    "cols = ['lda','qda','kmc-km++','kmc-rand','kmc-cent']\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "## test each feature\n",
    "res_feat = pd.DataFrame(columns=cols)\n",
    "for ft in X.columns.unique(level=0):\n",
    "    print('> Testing feature: ', ft)\n",
    "    res_feat.loc[ft, 'lda'] = m1_LDA(X.loc[:,pd.IndexSlice[ft, :, :]], y[yc])\n",
    "    res_feat.loc[ft, 'qda'] = m2_QDA(X.loc[:,pd.IndexSlice[ft, :, :]], y[yc])\n",
    "    res_feat.loc[ft, 'kmc-km++'] = m3_KMC(X.loc[:,pd.IndexSlice[ft, :, :]], y[yc], 'k-means++')\n",
    "    res_feat.loc[ft, 'kmc-rand'] = m3_KMC(X.loc[:,pd.IndexSlice[ft, :, :]], y[yc], 'random')\n",
    "    res_feat.loc[ft, 'kmc-cent'] = m3_KMC(X.loc[:,pd.IndexSlice[ft, :, :]], y[yc], 'centroids')\n",
    "\n",
    "## test each statistic\n",
    "res_stat = pd.DataFrame(columns=cols)\n",
    "for st in X.columns.unique(level=1):\n",
    "    print('> Testing statistic: ', st)\n",
    "    res_stat.loc[st, 'lda'] = m1_LDA(X.loc[:,pd.IndexSlice[:, st, :]], y[yc])\n",
    "    res_stat.loc[st, 'qda'] = m2_QDA(X.loc[:,pd.IndexSlice[:, st, :]], y[yc])\n",
    "    res_stat.loc[st, 'kmc-km++'] = m3_KMC(X.loc[:,pd.IndexSlice[:, st, :]], y[yc], 'k-means++')\n",
    "    res_stat.loc[st, 'kmc-rand'] = m3_KMC(X.loc[:,pd.IndexSlice[:, st, :]], y[yc], 'random')\n",
    "    res_stat.loc[st, 'kmc-cent'] = m3_KMC(X.loc[:,pd.IndexSlice[:, st, :]], y[yc], 'centroids')\n",
    "\n",
    "## print results\n",
    "print('Results by feature:\\n', res_feat)\n",
    "print('Results by statistic:\\n', res_stat)\n",
    "\n",
    "## export results\n",
    "res_feat.to_csv('res_feat_{}.csv'.format(yc))\n",
    "res_stat.to_csv('res_stat_{}.csv'.format(yc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> LDA Scores:\n",
      "Training score: 0.502\n",
      "Validation score: 0.491\n",
      "\n",
      "> LDA Scores:\n",
      "Training score: 0.478\n",
      "Validation score: 0.468\n",
      "\n",
      "> QDA Scores:\n",
      "Training score: 0.373\n",
      "Validation score: 0.349\n",
      "\n",
      "> QDA Scores:\n",
      "Training score: 0.346\n",
      "Validation score: 0.340\n",
      "\n",
      "> QDA Scores:\n",
      "Training score: 0.367\n",
      "Validation score: 0.338\n",
      "\n",
      "> KMeans Scores:\n",
      "Training score: 0.492\n",
      "Validation score: 0.497\n",
      "\n",
      "> KMeans Scores:\n",
      "Training score: 0.532\n",
      "Validation score: 0.532\n",
      "\n",
      "> KMeans Scores:\n",
      "Training score: 0.537\n",
      "Validation score: 0.534\n",
      "\n",
      "> KMeans Scores:\n",
      "Training score: 0.492\n",
      "Validation score: 0.499\n",
      "\n",
      "> KMeans Scores:\n",
      "Training score: 0.483\n",
      "Validation score: 0.482\n",
      "\n",
      "> KMeans Scores:\n",
      "Training score: 0.473\n",
      "Validation score: 0.477\n",
      "\n",
      "> Testing complete\n"
     ]
    }
   ],
   "source": [
    "m1_LDA(X.loc[:,pd.IndexSlice[:, :, :]], y['top_level'], verbose=True)\n",
    "m1_LDA(X.loc[:,pd.IndexSlice[['chroma_cens','mfcc','spectral_contrast'], :, :]], y['top_level'], verbose=True)\n",
    "\n",
    "qft = ['mfcc', 'spectral_bandwidth', 'spectral_centroid', 'spectral_contrast', 'spectral_rolloff', 'zcr']\n",
    "m2_QDA(X.loc[:,pd.IndexSlice[:, ['std'], :]], y['top_level'], verbose=True)\n",
    "m2_QDA(X.loc[:,pd.IndexSlice[qft, ['std'], :]], y['top_level'], verbose=True)\n",
    "m2_QDA(X.loc[:,pd.IndexSlice[qft, ['mean','median','std'], :]], y['top_level'], verbose=True)\n",
    "\n",
    "kft = ['mfcc', 'spectral_bandwidth', 'spectral_centroid', 'spectral_contrast', 'spectral_rolloff']\n",
    "m3_KMC(X.loc[:,pd.IndexSlice[['mfcc'], ['skew'], :]], y['genres_all'], verbose=True)\n",
    "m3_KMC(X.loc[:,pd.IndexSlice[['mfcc'], ['mean', 'median', 'skew'], :]], y['genres_all'], verbose=True)\n",
    "m3_KMC(X.loc[:,pd.IndexSlice[['mfcc'], :, :]], y['genres_all'], verbose=True)\n",
    "\n",
    "m3_KMC(X.loc[:,pd.IndexSlice[kft, ['skew'], :]], y['genres_all'], 'random', verbose=True)\n",
    "m3_KMC(X.loc[:,pd.IndexSlice[kft, ['mean', 'median', 'skew'], :]], y['genres_all'], 'random', verbose=True)\n",
    "m3_KMC(X.loc[:,pd.IndexSlice[kft, :, :]], y['genres_all'], 'random', verbose=True)\n",
    "\n",
    "print('> Testing complete')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
